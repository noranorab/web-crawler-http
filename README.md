# web-crawler-http

A web crawler operates by automatically following hyperlinks from one web page to another,
recursively visiting web pages and extracting data.
Web crawlers can also be used for various purposes such as data mining, content monitoring,
website analysis, or building web archives.
